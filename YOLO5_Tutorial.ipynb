{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Object Detection with YOLOv5\n",
        "Object detection is a computer vision technique that allows us to identify and locate objects within an image or video. YOLO (You Only Look Once) is a popular algorithm for object detection because of its speed and accuracy. YOLOv5 is one of the latest version of this algorithm (v8 is actually the latest now), and it's implemented in PyTorch, a powerful deep learning library."
      ],
      "metadata": {
        "id": "86RoPhOfvtVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Dependencies and Prepare the Environment\n",
        "\n",
        "* **!git clone https://github.com/ultralytics/yolov5:** This command clones the\n",
        "YOLOv5 GitHub repository into our Colab environment. It copies all the necessary files we need to run YOLOv5.\n",
        "\n",
        "* **%cd yolov5:** We change the current directory to the yolov5 folder that we just cloned. This is necessary because we need to be in the directory to install the dependencies.\n",
        "\n",
        "* **!pip install -r requirements.txt**: This installs the Python packages listed in the requirements.txt file, which includes all dependencies required by YOLOv5, such as PyTorch, Matplotlib (for plotting), and others.\n",
        "\n",
        "* **%cd ..:** Finally, we move back to the parent directory. It's a good practice to keep our working directory clean and organized."
      ],
      "metadata": {
        "id": "oOFGo1Hvv3eE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAHGyBvBvl5j"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tuVrPo2KfkVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load a Pre-trained YOLOv5 Model\n",
        "\n",
        "* **import torch**: We import PyTorch, which is the deep learning library that YOLOv5 is built with. PyTorch provides a range of tools for building and training neural networks.\n",
        "\n",
        "* **model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True):** This line loads a pre-trained YOLOv5 model from the PyTorch Hub. The 'yolov5s' argument specifies that we want to load the \"small\" version of YOLOv5, which is a balance between speed and accuracy, suitable for educational purposes and quick experiments. The pretrained=True parameter tells PyTorch to download a model that has already been trained on the COCO dataset, a large image dataset designed for object detection, segmentation, and captioning tasks."
      ],
      "metadata": {
        "id": "Xlt4pWVVxIgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"
      ],
      "metadata": {
        "id": "ZKT3moyJxQif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload and Prepare Your Images\n",
        "Before this step, you would manually upload images to Colab. Then, you specify the path to one of these images.\n",
        "\n",
        "* **Uploading Images**: In the Colab interface, you use the file upload feature to upload images from your local machine to the Colab environment. These images are then stored in the /content directory of Colab.\n",
        "\n",
        "* **'img = 'path/to/your/image.jpg'**: Here, you define a variable img that holds the path to the image you want to process. This path should be adjusted to match the location and name of your uploaded image."
      ],
      "metadata": {
        "id": "KU8DsBLUxTSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = 'path/to/your/image.jpg'\n",
        "results = model(img)\n",
        "results.show()"
      ],
      "metadata": {
        "id": "7Rli-37RxuMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment\n",
        "\n",
        "In this assignment, you will use the pre-trained YOLOv5 model to identify and classify products on supermarket shelves. The goal is to demonstrate how object detection can be applied to recognize various items from static images, simulating a simplified aspect of retail inventory management.\n",
        "\n",
        "**Objectives:**\n",
        "* Apply a pre-trained YOLOv5 model to detect objects within images of supermarket shelves.\n",
        "* Identify the types of products detected and their approximate quantities.\n",
        "\n",
        "\n",
        "**Materials:**\n",
        "* Use publicly available images of supermarket shelves.\n",
        "* Choose images with clear visibility of products, preferably with diverse\n",
        "items.\n",
        "\n",
        "**Steps:**\n",
        "* Step 1: Set Up Your Google Colab Environment\n",
        "Initialize a Google Colab notebook and set up the environment following the introductory guide's instructions, including cloning the YOLOv5 repository and installing dependencies.\n",
        "* Step 2: Collect Images\n",
        "Collect a set of images representing supermarket shelves. Ensure they are saved and accessible for processing in your Colab notebook.\n",
        "* Step 3: Apply the Pre-trained YOLOv5 Model\n",
        "Load the Pre-trained Model: As demonstrated in this tutorial, load the pre-trained YOLOv5 model using PyTorch Hub.\n",
        "Perform Object Detection: Use the model to detect objects in your collected images. This will involve running the detection command and visualizing the results with bounding boxes and labels.\n",
        "* Step 4:\n",
        "Analyze Detected Items: For each image, list the types of products detected and count the number of instances for each product type. Note any common items the model fails to detect or misclassifies.\n",
        "\n",
        "*Follow the template below*"
      ],
      "metadata": {
        "id": "cQslKYAkyqhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv5 for Product Identification in Supermarket Shelves - Assignment Scaffold\n",
        "\n",
        "# Before starting, make sure to upload your supermarket shelf images to Google Colab\n",
        "\n",
        "# Step 1: Setup Environment\n",
        "# Install necessary libraries and clone YOLOv5 repository. Uncomment and run the following commands.\n",
        "'''\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt\n",
        "%cd ..\n",
        "'''\n",
        "\n",
        "# Import necessary libraries. Add any additional imports you might need.\n",
        "import torch\n",
        "# Add import statement for displaying images in Colab\n",
        "\n",
        "# Step 2: Load Pre-trained YOLOv5 Model\n",
        "# Load the pre-trained model from PyTorch Hub. You can choose different versions of YOLOv5 (e.g., 'yolov5s', 'yolov5m').\n",
        "'''\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "'''\n",
        "\n",
        "# Step 3: Perform Object Detection on Collected Images\n",
        "# Function to perform object detection and display results. Complete this function based on the instructions.\n",
        "def detect_and_display(image_path):\n",
        "    # Use the loaded model to perform object detection on the image_path provided.\n",
        "    # Display the image with detections. Look up the YOLOv5 documentation for guidance.\n",
        "\n",
        "    # Placeholder for detection code\n",
        "    '''\n",
        "    results = model(image_path)\n",
        "    results.show()\n",
        "    '''\n",
        "\n",
        "    # Extract and print a summary of detected objects. This is partially done for you; complete it as instructed.\n",
        "    '''\n",
        "    detected_objects = results.pandas().xyxy[0]['name']\n",
        "    print(\"\\nDetected Products Summary:\")\n",
        "    # Iterate through detected_objects to count and print instances of each unique object\n",
        "    '''\n",
        "\n",
        "# Example call to the detect_and_display function with a placeholder path\n",
        "# Replace 'path/to/your/image.jpg' with the path to your actual image\n",
        "# detect_and_display('path/to/your/image.jpg')\n",
        "\n",
        "# Step 4: Analysis\n",
        "# After running your detections, analyze the results in the context of retail inventory management.\n",
        "# Consider accuracy, potential retail applications, and any limitations of the technology.\n",
        "# Write your analysis as comments or in a separate document.\n",
        "\n",
        "'''\n",
        "# Example Analysis (replace this with your actual analysis):\n",
        "# - The YOLOv5 model detected X, Y, Z objects with high accuracy.\n",
        "# - Potential applications in retail include inventory tracking, automated checkout, and shelf stocking.\n",
        "# - Limitations may include the need for high-quality images and challenges in detecting overlapped items.\n",
        "'''\n"
      ],
      "metadata": {
        "id": "080Gz6BJ0Vg5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}